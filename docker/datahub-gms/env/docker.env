DATASET_ENABLE_SCSI=false
EBEAN_DATASOURCE_USERNAME=smartnews
EBEAN_DATASOURCE_PASSWORD=smartnews
EBEAN_DATASOURCE_HOST=airflow.c6xrdianp1t4.ap-northeast-1.rds.amazonaws.com:3306
EBEAN_DATASOURCE_URL=jdbc:mysql://airflow.c6xrdianp1t4.ap-northeast-1.rds.amazonaws.com:3306/datahub?verifyServerCertificate=false&useSSL=true&useUnicode=yes&characterEncoding=UTF-8
EBEAN_DATASOURCE_DRIVER=com.mysql.jdbc.Driver
KAFKA_BOOTSTRAP_SERVER=broker.data-catalogue.svc.cluster.local:29092
KAFKA_SCHEMAREGISTRY_URL=http://schema-registry.data-catalogue.svc.cluster.local:8081
ELASTICSEARCH_HOST=elasticsearch.data-catalogue.svc.cluster.local
ELASTICSEARCH_PORT=9200
NEO4J_HOST=http://neo4j.data-catalogue.svc.cluster.local:7474
NEO4J_URI=bolt://neo4j.data-catalogue.svc.cluster.local
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=datahub

# Uncomment to configure kafka topic names
# Make sure these names are consistent across the whole deployment
# METADATA_AUDIT_EVENT_NAME=MetadataAuditEvent_v4
# METADATA_CHANGE_EVENT_NAME=MetadataChangeEvent_v4
# FAILED_METADATA_CHANGE_EVENT_NAME=FailedMetadataChangeEvent_v4

# Uncomment and set these to support SSL connection to Elasticsearch
# ELASTICSEARCH_USE_SSL=true
# ELASTICSEARCH_SSL_PROTOCOL=TLSv1.2
# ELASTICSEARCH_SSL_SECURE_RANDOM_IMPL=
# ELASTICSEARCH_SSL_TRUSTSTORE_FILE=
# ELASTICSEARCH_SSL_TRUSTSTORE_TYPE=
# ELASTICSEARCH_SSL_TRUSTSTORE_PASSWORD=
# ELASTICSEARCH_SSL_KEYSTORE_FILE=
# ELASTICSEARCH_SSL_KEYSTORE_TYPE=
# ELASTICSEARCH_SSL_KEYSTORE_PASSWORD=

# To use simple username/password authentication to Elasticsearch over HTTPS
# set ELASTICSEARCH_USE_SSL=true and uncomment:
# ELASTICSEARCH_USERNAME=
# ELASTICSEARCH_PASSWORD=
